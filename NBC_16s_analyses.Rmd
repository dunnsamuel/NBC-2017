---
title: "Community Analyses (16s)"
author: "Sam Dunn"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  
  word_document: default
  pdf_document: default
  html_document:
    df_print: paged
---
## Introduction
This document will guide you through some analyses for microbial communities.  The code below was written with Bacteria in mind, but can be applied to Algae or Fungi sequences as well as long as Mothur has been used to prepare the taxonomy summary table (see mothur documentation).

In this document I will highlight areas where a user would need to change the code in order to apply it to their data.  This mainly has to deal with the way samples are labelled and experimental groups are organized (i.e. I compare Substrates, you may compare Sites, etc.).  Apart from this I do not advise editing the code unless you have first saved the original copy somewhere and are prepared to troubleshoot.  Additionally, these analyses represent only a very small subset of common community metrics and this document is by no means an exhaustive one.  The R users on twitter (#rstats) and on stack-overflow are VERY helpful and genuinely want to help people learn how to do this, so don't be afraid to ask for help!


## The Data Source
This is the graphing and statistical analyses for the 16s sequences collected for the NBC project in 2017.  Analyses began in Mothur on April 4th 2018 and were completed on April 18th 2018.  A taxonomic summary was exported from mothur to R on 4/19/2018 and edits have been ongoing.  This document was annotated and finalized in October 2018 as Sam was preparing to leave Loyola for another position doing data science.  If all else fails, Sam can be reached at Samuel.t.Dunn@gmail.com

## Loading Packages and Data
In Mothur we created a tax summary table at he end of our process that we now will import here.  In R you should already have a Project set up that is associated with a git repository.  If not, go do that now and come back.  In order for R to see your tax summary table, move it into the newly created project folder.   In the following code chunk, change the file name (in "") to match your own...don't forget the file extension!  If you don't have a .csv file use the "read_delim" code that has been #out.
```{r Load Data and Packages, warning=FALSE,message=FALSE}

bacteria.df=read.csv("nbc16s.final.subsample.tax.summary.csv") #csv formatted data from mothur
#its.df<-read.delim(file="nbcits.final.an.0.01.cons.tax.summary") #otherwise formatted data from mothur

##Loading Packages
# ipak function: install and load multiple R packages.
# checks to see if packages are installed. Install them if they are not, then load them into the R session.

ipak <- function(pkg){
    new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
    if (length(new.pkg)) 
        install.packages(new.pkg, dependencies = TRUE, repos='http://cran.us.r-project.org')
    sapply(pkg, require, character.only = TRUE)
}

# Package list.  Contains all needed packages as a this writing.  To update, simply add new package name to the list!
packages <- c("ggplot2", 
              "plyr", 
              "reshape2", 
              "RColorBrewer", 
              "scales", 
              "grid",
              "VennDiagram",
              "bibtex",
              "vegan",
              "RAM",
              "tidyr",
              "Rmisc",
              "glue",
              "reshape",
              "reshape2",
              "lemon",
              "gapminder",
              "magrittr",
              "dplyr",
              "ggpubr",
              "gridExtra",
              "patternplot",
              "tibble",
              "gplots",
              "broom",
              "data.table",
              "devtools",
              "xlsx",
              "ggrepel")
ipak(packages)

#PAirwise adonis is an unofiical package that does pairwise PERMANOVA on community data.  it is marginally useful.  To active it, simply remove the # and re run the code.
#install_github("pmartinezarbizu/pairwiseAdonis/pairwiseAdonis")
#library(pairwiseAdonis)

pd=position_dodge(width=0.8)

bacteria.df=bacteria.df[bacteria.df$taxon !="Chloroplast_ge",] #We forgot to remove chloroplasts before in mothur...but we can do it now too!


```


## Shannon Diversity
There are many resources for you to learn about Shannon diversity...this is not one.  I will show you how to calculate it for your data.  But first, a quick data science topic.  In data we often discuss "tall" and "wide" data sets. The data we have mothur give us in our summary table is "wide" data and in order to calculate Shannon diversity we need wide data.  What is wide data?  A wide datasheet has a column for each (in this case) sample.  By contrast a tall data set would have 
The "vegan" package is for diversity and other community metrics, the "RAM" packages is for evenness (vegan doesn't have it for some reason). 

The annotation for data preparation will be heaviest in this first code chunk.  Each chunk is able to stand alone, and a a result we often repeat ourselves.  When things begin to differ I will add back in annotation.

```{r Shannon Diversity,warning=FALSE}

bacteria.df$taxlevel=as.factor(bacteria.df$taxlevel) #make sure taxlevel is a factor so we can pull out data  in the following analyses
bacteria.df.6=subset.data.frame(bacteria.df, taxlevel==6,drop=TRUE)  #6 is the species level  #kingdom=0
#phylum=1
#class=2
#order=3
#family=4
#genus=5
#species=6


#you'll have to update your first and last sample column name in the "vars" argument below.  You will also need to look at your sample (column) names and adjust the arguments in the separate function.  Briefly, change the arguments int he "into" list to represent the number o chunks you can split your sample name into.  Secondly,the "sep"  says how many places fromt he left or right(-) the cuts should be made to separate.  The number of values in sep should each the number of groups in into less 1.
shannon.nbc<-bacteria.df.6 %>% 
  subset(select=c(-taxlevel,-rankID,-taxon,-daughterlevels,-total)) %>% #IF YOU HAVE CONTROLS< YOU CAN 
  mutate_at(vars(X170818HA:X170828HB),funs(diversity(.,index="shannon"))) %>% #MAKE SURE YOUR COLLUMNS MAKE SENSE
  gather(key="Sample",value="Diversity") %>%
  distinct(Sample,Diversity) %>% 
  separate(Sample, into=c("junk","Date","Substrate","Rep"), sep=c(1,7,-1))
  

#Clean up time.  First we remove the junk column altogether.  seconldy, we do some cleaning in case controls made it in.  Lastly we want to convert our "date" code into a "day of incuation" which we do manually with the revalue function.
shannon.nbc$junk=NULL
shannon.df=droplevels(shannon.nbc[-which(shannon.nbc$Substrate=='CR'),])
shannon.df$Date=as.factor(shannon.df$Date)
shannon.df$Date=revalue(shannon.df$Date,c("170818"="3","170828"="10","170905"="21","170915"="31"))
shannon.df$Substrate=factor(shannon.df$Substrate,levels=c("H","SO","SH","F","T"),labels=c("PVC","Soft PE","Sheet PE","PS","Tile"))


#Now, we summarizse by Date and Susbtrate  and get means and se across our reps.  
shannon.div.summary<-shannon.df %>% 
  group_by(Date, Substrate) %>% 
  summarise(mean=mean(Diversity),se=(sd(Diversity)/sqrt(n())))
                          

#Lets plot our summarizes data.
#tell ggplot what data to plot and the basic aesthtetichs (aes) we want a line graph connecting points.  Date is on the x axis and the mean is on the y.  We are grouping them and adjustign their shape and colors by type of substrate.
#adds points and lines to the plot

shannon.div.16s=ggplot(shannon.div.summary,  aes(x=Date,y=mean,group=Substrate,shape=Substrate,fill=Substrate))+ 
  geom_point(position=pd,size=4)+
  geom_line(aes(linetype=Substrate),position=pd)+ 
  geom_errorbar(aes(ymin=mean-se,ymax=mean+se),width=0.3,position=pd)+
  ylab("Shannon Diversity (H')")+ 
  theme_classic()+ #good generla theme for clean figures
  theme(legend.position=c(0.25,0.95), #legends are ifnitiely tweakable
        legend.title=element_blank(),
        legend.direction="horizontal",
        axis.text=element_text(size=16),
        axis.title=element_text(size=16),
        legend.text=element_text(size=14))+
  scale_shape_manual(name="Substrate",values=c(21,22,23,24,25))+ #I manually changed the shape of th points.  tehre is great additional supporting info online
  ggtitle("Bacterial Communities")+
  scale_y_continuous(breaks=seq(0,5,0.1)) #for consistency I am telling it to sacel y axis from 0 to 5 by 0.1 intervals
shannon.div.16s #calls (views) the graph we made


shannon.div.16s.bw=ggplot(shannon.div.summary,  aes(x=Date,y=mean,group=Substrate,shape=Substrate))+ 
  geom_point(position=pd,size=4,fill="black")+
  geom_line(aes(linetype=Substrate),position=pd)+ 
  geom_errorbar(aes(ymin=mean-se,ymax=mean+se),width=0.3,position=pd)+
  ylab("Shannon Diversity (H')")+ 
  theme_classic()+ #good generla theme for clean figures
  theme(legend.position=c(0.25,0.95), #legends are ifnitiely tweakable
        legend.title=element_blank(),
        legend.direction="horizontal",
        axis.text=element_text(size=16),
        axis.title=element_text(size=16),
        legend.text=element_text(size=14))+
  scale_shape_manual(name="Substrate",values=c(21,22,23,24,25))+ #I manually changed the shape of th points.  tehre is great additional supporting info online
  ggtitle("Bacterial Communities")+
  scale_y_continuous(breaks=seq(0,5,0.1)) #for consistency I am telling it to sacel y axis from 0 to 5 by 0.1 intervals
shannon.div.16s.bw 

#ggsave lets you print your plots to jpegs, pdf, etc.  Just adjust the filename and device accordingly

#ggsave(shannon.div.16s,filename="shannon_plot.pdf",device="pdf")


#Stats time
shan.anova<-tidy(aov(Diversity~Date+Substrate+Date:Substrate,data=shannon.df))
shan.anova #this is its own dataframe now....you could easily export this to excel using the write_csv function!

```




## Richness
Since the species concept doesn't work too well with bacteria (screw you lateral gene transfer).  We will define unique otus (operational taxonomic units).  I select only taxa that are present by defining an observation Threshold.  This could be re-worked to eliminate singletons for future work.

```{r OTU count (richness), warning=FALSE}
bacteria.df$taxlevel=as.factor(bacteria.df$taxlevel)
bacteria.df.6=subset.data.frame(bacteria.df, taxlevel==6,drop=TRUE)

otu.df<-bacteria.df.6 %>% 
  subset(select=c(-taxlevel,-rankID,-taxon,-daughterlevels,-total)) %>% 
  mutate_at(vars(X170818HA:X170828HB),funs(n_distinct(.))) %>% #We calculate the number of distinct taxa here!
  gather(key="Sample",value="OTU") %>%
  distinct(Sample,OTU) %>% 
  separate(Sample, into=c("junk","Date","Substrate","Rep"), sep=c(1,7,-1))


otu.df$junk=NULL
otu.df=droplevels(otu.df[-which(otu.df$Substrate=='CR'),])
otu.df$Date=as.factor(otu.df$Date)
otu.df$Date=revalue(otu.df$Date,c("170818"="3","170828"="10","170905"="21","170915"="31"))
otu.df$Substrate=factor(otu.df$Substrate,levels=c("H","SO","SH","F","T"),labels=c("PVC","Soft PE","Sheet PE","PS","Tile"))






otu.df.summary=summarySE(otu.df,measurevar="OTU",groupvars=c("Date","Substrate"),na.rm=TRUE)
#This is another, simpler form of summarizing info for plotting purposes.  I chose to leave this here as an example of how making a summary table works if you don't have to do it multiple times.

pd=position_dodge(width=0.4)

otu.plot=ggplot(otu.df.summary, 
                aes(x=Date,y=OTU,group=Substrate,shape=Substrate,fill=Substrate))+
  geom_point(position=pd,size=4)+
  geom_line(aes(linetype=Substrate),position=pd)+
  geom_errorbar(aes(ymin=OTU-se,ymax=OTU+se),width=0.3,position=pd)+
  ylab("Observed OTUs")+
  theme_classic()+
  theme(legend.position=c(0.25,0.95),
        legend.title=element_blank(),
        legend.direction="horizontal",
        axis.text=element_text(size=16),
        axis.title=element_text(size=16),
        legend.text=element_text(size=14))+
  scale_shape_manual(name="Substrate",values=c(21,22,23,24,25))
otu.plot

otu.anova<-tidy(aov(OTU~Date+Substrate+Date:Substrate,data=otu.df))
otu.anova #this is its own dataframe now....you could easily export this to excel using the write_csv function!

```

From here on out the taxonomic cutoff set for genus level, can restrict to phylum to match up with stacked bar plots below.  Stacked bar plots are not my favorite, but they are a good first cut for finding patterns.


## Stacked Bars
Great exploration tool ,but user be warned they can get very hard to read!  We will practice having R do multiple things at once for us.  In general if you find yourself writing the same code over and over again you can probably automate that (but not always!)

```{r Stacked Bar Plots,warning=FALSE,message=FALSE}

#slightly different approach here.  We are removign columns instead of ignoring them like we have previously.  This is because ti's a little cleaner to do so and this analsyis is a little mroe ocmplicated.
bacteria.df.3=subset.data.frame(bacteria.df, taxlevel==2,drop=TRUE)
bacteria.df.3$taxlevel=NULL 
bacteria.df.3$rankID=NULL
bacteria.df.3$daughterlevels=NULL
bacteria.df.3$total=NULL

bac.rab<-bacteria.df.3 %>% 
  gather(-taxon,key="Sample",value="obs") 
  
bac.rab<-bac.rab %>%   #relative abundance calculations
  group_by(Sample) %>% 
  mutate(total_obs=sum(obs),
         rabund=obs/total_obs) %>% 
  separate(Sample, into=c("Junk","Date","Substrate","Rep"),sep=c(1,7,-1))



bac.rab$Junk=NULL
rabund.df=droplevels(bac.rab[-which(bac.rab$Substrate=='CR'),])
rabund.df$Date=as.factor(rabund.df$Date)
rabund.df$Date=revalue(rabund.df$Date,c("170818"="3","170828"="10","170905"="21","170915"="31"))
rabund.df$Substrate=factor(rabund.df$Substrate,levels=c("H","SO","SH","F","T"),labels=c("PVC","Soft PE","Sheet PE","PS","Tile"))


rabund.sum.df<-rabund.df %>% 
  group_by(Date,Substrate,taxon) %>% #note the inlcusion of taxon as a group to summarise by.  We want the mean of each taxon in each Date-Substrate combination
  summarise(mean_rabund=mean(rabund),
            mean_obs=mean(obs))


##making multiple plots!
rabund.plots<-rabund.sum.df %>% #generates list of plots by Date (groubp_by command)  
  group_by(Date) %>% 
  do(plots=ggplot(.,aes(x=Substrate,y=mean_rabund,group=taxon,color=taxon,fill=taxon))+
       geom_bar(stat="identity",color="black")+
       ggtitle(paste("Day",.$Date))+ #.$Date is shorthand to pull int he value of date for the given group being produced.  Using patse allows us to add extra text.
       ylab("Relative Abundance")+
       xlab("Substrate")+
       theme_classic())
rabund.plots$plots[[1]] #calls first plot from list of plots. Repeat for as many plots as you expect




```

##
Making the same plot over and over again is tedious.  We can usually automate this by following a process similar to that above.  In situations where there are lots of data and lots of groups this can potentially take a while to run.  Also, it is good advice to never have it print the first time your try running it...just in case something is fishy.


## Heat-maps
There are 16 millions color shades in R....and this makes it hard to see subtle changes.  Heat-maps offer another visual tool to get an overview of your community.  We add in facets to allow us t compare different Substrates, times, etc.

```{r heatmap,warning=FALSE,message=FALSE, fig.height=11,fig.width=8.5,fig.align="center"}

bacteria.df.3=subset.data.frame(bacteria.df, taxlevel==2,drop=TRUE) #Note the higher tax level...purely from a visualization standpoint
bacteria.df.3$taxlevel=NULL
bacteria.df.3$rankID=NULL
bacteria.df.3$daughterlevels=NULL
bacteria.df.3$total=NULL
bac.rab<-bacteria.df.3 %>% 
  gather(-taxon,key="Sample",value="obs") 
  
bac.rab<-bac.rab %>%   
  group_by(Sample) %>% 
  mutate(total_obs=sum(obs),
         rabund=obs/total_obs)



bac.rab<-separate(bac.rab,Sample, into=c("Junk","Date","Substrate","Rep"),sep=c(1,7,-1)) 
bac.rab$Junk=NULL

rabund.df=droplevels(bac.rab[-which(bac.rab$Substrate=='CR'),])
rabund.df$Date=as.factor(rabund.df$Date)
rabund.df$Date=revalue(rabund.df$Date,c("170818"="3","170828"="10","170905"="21","170915"="31"))
rabund.df$Substrate=factor(rabund.df$Substrate,levels=c("H","SO","SH","F","T"),labels=c("PVC","Soft PE","Sheet PE","PS","Tile"))

rabund.sum.df<-rabund.df %>% 
  group_by(Date,Substrate,taxon) %>% 
  summarise(mean_rabund=mean(rabund),
            mean_obs=mean(obs))



require(viridis) #viridis is a package of alternative color scales to allow for high contrast observations....i.e. whent here are very subtle changes.
ggplot(rabund.sum.df, aes(Date,taxon,fill=mean_rabund))+
  geom_tile(width=1)+
  facet_wrap(~Substrate,nrow=1)+#facet wrap splits our graph into multiuple chunks where each has a unique valeu for some factor
  scale_fill_viridis_c(name="Root Mean Relative\nAbundance")+  #\n creates a line break in text
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=10),
        strip.text=element_text(size=10),
        legend.title = element_text(size=12))+
  ylab("Phylum")+
  xlab("Day of Incubation")
  
ggsave("bac.hm.jpeg", device="jpeg", width=8, height=10,units="in")
#you can also set dimensions when your print your figures
```



## Multivariate Stats and Visualizations

Switching gear, lets approach this from a multivariate approach.  Ordination approaches allow us to plot our community data in two dimensions very well. We do this by first calculating a distance matrix (Bray Curtis usually) and then conduct and NMDS on he distance matrix.  With the envfit function we can correlate our environmental and laboratory assays with our nmds results to try and find explanatory power.  

```{r Envfit plots,warning=FALSE,messages=FALSE}
env.df <- read.csv("env.df.csv") #external data for vector fitting (laba ssays, field data,etc)
env.drops=c("8/15/2017",
            "8/22/2017",
            "8/25/2017",
            "9/1/2017",
            "9/8/2017",
            "9/12/2017") #beware of date format shifts in excel!!  I am dropping dates from the env.df because I didn't get community measurements for each date


env.df=droplevels(env.df[!(env.df$Date.Sampled %in% env.drops),],drop=TRUE)
colnames(env.df)=c("Date_Sampled",
                   "Substrate",
                   "NEP",
                   "GPP",
                   "Respiration",
                   "BG-ase",
                   "NAG-ase",
                   "P-ase",
                   "Chl.a",
                   "Biomass",
                   "Day of Incubation",
                   "SRP",
                   "NO3",
                   "NH4",
                   "doy",
                   "width",
                   "xdepth",
                   "xvelocity",
                   "xtemp",
                   "xspc",
                   "Q")

env.c.drops=c("X",  #I don't necessarily want to use all the data here, so I specified some columns to ignore (summary columns, duplicates, etc)
              "Date.Sampled",
              "Sample",
              "time",
              "doy",
              "width",
              "xdepth",
              "xvelocity",
              "xtemp",
              "xspc",
              "Q")


env.df.fit=env.df[ , !(names(env.df) %in% env.c.drops)] #this si the code to remove the specified columns. ! is the remove command (or retain all except)



bacteria.df.3=subset.data.frame(bacteria.df, taxlevel==3,drop=TRUE)
bacteria.df.3$taxlevel=NULL
bacteria.df.3$rankID=NULL
bacteria.df.3$daughterlevels=NULL
bacteria.df.3$total=NULL

bac.env<-bacteria.df.3 %>% 
  gather(-taxon,key="Sample",value="obs") %>% 
  separate(Sample, into=c("Junk","Date","Substrate","Rep"),sep=c(1,7,-1))

bac.env$Junk=NULL
bac.env=droplevels(bac.env[-which(bac.env$Substrate=='CR'),])
env.df$Date_Sampled=as.factor(env.df$Date_Sampled)
env.df$Date_Sampled=revalue(env.df$Date_Sampled,c("8/18/2017"="3","8/29/2017"="10","9/5/2017"="21","9/15/2017"="31"))
env.df$Substrate=factor(env.df$Substrate,levels=c("H","So","Sh","F","T"),labels=c("PVC","Soft PE","Sheet PE","PS","Tile"))

end.df.names=c("Date_Sampled","Substrate")
env.df.fac=env.df[,names(env.df) %in% end.df.names] #We want to copy the first two columns of site  data here.  We can't have ANY site data present when we do our ordination.  We will reattache this site data tot he ordination table afterwards so we can make inferences and good figures.

bac.df.sps<-bac.env %>% 
  spread(key=taxon, value=obs) %>% 
  dplyr::select(-Date,-Substrate,-Rep)#spread take a tall data table and makes it wide.  each "key" value becomes a column populated by the "value"
  


bac.ord.dist=vegdist(bac.df.sps) #vegdist in the vegab package does distances.  Bray-Curtis is default but can do many many more.
bac.ord.nmds=metaMDS(bac.ord.dist) # We use our distance matrix fromt he above line to run our NMDS
bac.ORD=data.frame(MDS1=bac.ord.nmds$points[,1],MDS2=bac.ord.nmds$points[,2])# We want to extract the X and Y coordinates for our NMDS.  
bac.ORD=cbind(bac.ORD,env.df.fac) # We paste our site data extracted above to our NMKS coordinates so we cna make figures, etc.

bac.fit=envfit(bac.ord.nmds,env.df.fit,perm=999,na.rm=T,display="sites") #Envfit is a vector fitting fucntiont hat can identify correlations between NMDS points and other data.  This is more appropriate to use on SITE data with COMMUNITY NMDS.    
#bac.fit
bac.fit.df=as.data.frame(bac.fit$vectors$arrows*sqrt(bac.fit$vectors$r)) #exracting the data to plot the vectors
bac.fit.df$species=rownames(bac.fit.df) #converting rownmaes (inaccesible data) to a column (accessible data)
bac.spp.scrs=as.data.frame(scores(bac.fit,display="vectors"))
bac.spp.scrs=cbind(bac.spp.scrs, Assay=rownames(bac.spp.scrs),bac.fit$vectors$pvals) #Combining vector coordinates, pvalues etc into a data table for plotting 
bac.spp.scrs=setnames(bac.spp.scrs, old=("bac.fit$vectors$pvals"), new=c("pvals")) #Changing the name for clarity's sake
bac.spp.scrs=bac.spp.scrs[ which (bac.spp.scrs$pvals<0.05),] #Here we select only the  vectors whose p.vals are less than 0.05.



#Plotting oru NDMS
bac.nmds=ggplot()+
  geom_point(data=bac.ORD ,aes(x=MDS1,y=MDS2, shape=Substrate,fill=Date_Sampled,color=Date_Sampled),size=3)+
  coord_fixed(ratio=1)+
  geom_segment(data=bac.spp.scrs, #lines for vectors
               aes(x=0, xend=bac.spp.scrs$NMDS1/4, y=0,yend=bac.spp.scrs$NMDS2/4),
               arrow=arrow(length=unit(.1, "cm")),
               color="red")+
  geom_text_repel(data = bac.spp.scrs, #labels for vectors
            aes(x = NMDS1/4, y = NMDS2/4, label = Assay),
            size = 3) +
  ggtitle("Bacterial Communities")+
  scale_fill_viridis_d("Day of Incubation")+
  scale_color_viridis_d("Day of Incubation")+
  scale_shape_manual(name="Substrate",values=c(21,22,23,24,25))+
  theme_classic()#+
  #labs(shape="Substrate", fill="Date Sampled")
bac.nmds

## The scores and stress values are important metrics of NMDS quality
#scores(bac.fit, "vectors")
#bac.ord.nmds$stress


## These plots  use the facet grod approach to pull out the plot for each level of a factor (types of substrate for sinatcne)
ggplot(bac.ORD)+
  geom_point(mapping= aes(MDS1,MDS2,shape=Date_Sampled,color=Substrate,group=Substrate))+
  facet_grid(.~Date_Sampled)

ggplot(bac.ORD)+
  geom_point(mapping= aes(MDS1,MDS2,shape=Date_Sampled,color=Substrate,group=Substrate))+
  facet_grid(.~Substrate)


#This section should really be its own chunk, but since it relies directly on the distance matrices we just calculated it makes sense to just keep it here.  
#betadisper compares the area of the collected nmds points for each group you specifiy and compares it to your other group areas (a la anova).  It is analgous to homogeneity of variance test and is a great way to visualize your ordination.

#http://cc.oulu.fi/~jarioksa/softhelp/vegan/html/betadisper.html
bac.disp.Sample=betadisper(bac.ord.dist,bac.ORD$Substrate) #Grouping by Substrate type
bac.disp.Date=betadisper(bac.ord.dist,bac.ORD$Date_Sampled) #Grouping by Date
bac.perm.date=permutest(bac.disp.Date, pairwise=TRUE,permutations=1000) #analgous to an anova
TukeyHSD(bac.disp.Sample) #compaitble with tukeyhsd for pairwise comparions!  Are there significant differences in variances between our groups?
bac.perm.sample=permutest(bac.disp.Sample, pairwise=TRUE,permutations=1000)
TukeyHSD(bac.disp.Date)
bac.disp.Sample #lets plots the results.  NOte the use of capiatlization and lower case in the last term name....this is intentional!
bac.disp.Date
#test pairwise comparions between groups in nmds


```

## PERMANOVA
Okay.  So, we probably don't have any differences between our groups, but let's find out for certain.  PERMANOVA is the analysis of variance using distance matrices (bray-curtis in our case).  It is non-parametric and robust to non-normal data.  However, it does require that there be no missing data.  The approach here is very similar to that of the envfit and NMDS section above.  however in this case we don't visualize our results as a figure, but rather a a table.

```{r PERMANOVA, warning=FALSE}
bacteria.df.6=subset.data.frame(bacteria.df, taxlevel==6,drop=TRUE)
bacteria.df.6$taxlevel=NULL
bacteria.df.6$rankID=NULL
bacteria.df.6$daughterlevels=NULL
bacteria.df.6$total=NULL
bac.perm<-bacteria.df.6 %>% 
  gather(-taxon,key="Sample",value="obs") 




bac.perm<-separate(bac.perm,Sample, into=c("Junk","Date","Substrate","Rep"),sep=c(1,7,-1)) 
bac.perm$Junk=NULL

bac.perm=droplevels(bac.perm[-which(bac.perm$Substrate=='CR'),])
bac.perm$Date=as.factor(bac.perm$Date)
bac.perm$Date=revalue(bac.perm$Date,c("170818"="3","170828"="10","170905"="21","170915"="31"))
bac.perm$Substrate=factor(bac.perm$Substrate,levels=c("H","SO","SH","F","T"),labels=c("PVC","Soft PE","Sheet PE","PS","Tile"))

anosim.bac.df<-bac.perm %>% #originally I was trying to use ANOSIM, but PERMANOVA ended up being mroe appropriate...I was too lazy to change the names.
  spread(key="taxon",value="obs")

#The above is all the same as you've seen ebfore.  It may seem redundant, but it is very important that every analysis be able to stand alone if need be.  This saves time on computation (you don't have to re-run the whole file) and makes it much mroe shareable.





design.df=anosim.bac.df[,1:3] #We create a design dataframe fromt he Date, Substrate and Rep columns.  Just like before we can't have any non-numeric data present for the matrix caclulations.  This time we will call this design file directly in the function call.

#remove the design file columns from the matrix
anosim.bac.df$Date=NULL
anosim.bac.df$Substrate=NULL
anosim.bac.df$Rep=NULL

#Here we are creating distances for the PERMANOVA
bac.dist=vegdist(anosim.bac.df)
bac.ano=anosim(bac.dist,design.df$Substrate) # I left ANOSIM in here just for kicks.  Read about it here 
summary(bac.ano)


# Running the permanova
bac.perm=print(adonis(anosim.bac.df~Substrate*Date,data=design.df)) #the adonis() function is what calculates the PERMANOVA.  The interaction term is automatic and does not need to explicitly coded
bac.perm.tab=as.data.frame(bac.perm$aov.tab)
bac.perm.tab=bac.perm.tab[1:3,]
bac.perm.tab<-rownames_to_column(bac.perm.tab,var="Parameter") #createing a term column from rownames
bac.perm.tab # prints the table

write.xlsx(bac.perm.tab,"permanova.table.xlsx")

## Pairwise adonis is a user-created function on github.  It can be marginally helpful so I left it here but de-activated.
#pairwise.adonis(anosim.df,factors=c(design.df$Substrate), 
              #  sim.method = 'bray', 
              #  p.adjust.m ='bonferroni')

#pairwise.adonis(anosim.df,factors=c(design.df$Date), 
              #  sim.method = 'bray', 
              #  p.adjust.m ='bonferroni')

```
## Venn Diagrams
We want to know whether the communities are different  between substrates.  Venn Diagrams are great visualization tools but are surprisingly poorly supported in R.  The basic logic is as follows.  Create a list of taxa associated with each group.  Compare these lists and count where lists match.  Sounds easy, right?  It is surprisingly difficult.  Proceed with caution.
```{r Venn Diagrams,warning=FALSE}
#extract and shape OTU table at Order level
bacteria.df.venn=subset.data.frame(bacteria.df, taxlevel==4,drop=TRUE)
drops <- c("taxlevel","rankID","daughterlevels","total","SDKC1","SDKC2","SDKC3")
bacteria.df.venn=bacteria.df.venn[ , !(names(bacteria.df.venn) %in% drops)]


#Data Prep
bacteria.df.venn=melt(bacteria.df.venn,id.vars="taxon") #melt is an older version of spread() we use everywhere else
bacteria.df.venn=dcast(bacteria.df.venn,variable~bacteria.df.venn$taxon) #dcast is an older version of gather()
bacteria.df.venn=separate(bacteria.df.venn,variable,into=c("junk","Date","Substrate"),sep=c(1,7))
bacteria.df.venn=separate(bacteria.df.venn,Substrate,into=c("Substrate","Rep"),sep=c(-1))
bacteria.df.venn$junk=NULL

bacteria.df.venn=droplevels(bacteria.df.venn[-which(bacteria.df.venn$Substrate=='CR'),])
bacteria.df.venn$Date=as.factor(bacteria.df.venn$Date)
bacteria.df.venn$Date=revalue(bacteria.df.venn$Date,c("170818"="3","170828"="10","170905"="21","170915"="31"))


#Creating lists for each substrate type
Hard=colnames(bacteria.df.venn[bacteria.df.venn$Substrate=="H",
                               apply(bacteria.df.venn[bacteria.df.venn$Substrate=="H",],
                                     MARGIN=2,function(x) any(x>0))])
Hard=Hard[-(1:3)]#dumps the extra stuff we don't need (-)denotes deletion

Soft=colnames(bacteria.df.venn[bacteria.df.venn$Substrate=="SO",
                               apply(bacteria.df.venn[bacteria.df.venn$Substrate=="SO",],
                                     MARGIN=2,function(x) any(x>0))])
Soft=Soft[-(1:3)]

Sheet=colnames(bacteria.df.venn[bacteria.df.venn$Substrate=="SH",
                                apply(bacteria.df.venn[bacteria.df.venn$Substrate=="SH",],
                                      MARGIN=2,function(x) any(x>0))])
Sheet=Sheet[-(1:3)]

Foam=colnames(bacteria.df.venn[bacteria.df.venn$Substrate=="F",
                               apply(bacteria.df.venn[bacteria.df.venn$Substrate=="F",],
                                     MARGIN=2,function(x) any(x>0))])
Foam=Foam[-(1:3)]

Tile=colnames(bacteria.df.venn[bacteria.df.venn$Substrate=="T",
                               apply(bacteria.df.venn[bacteria.df.venn$Substrate=="T",],
                                     MARGIN=2,function(x) any(x>0))])
Tile=Tile[-(1:3)]


bac.venn.list=list("Hard"=Hard,"Soft"=Soft,"Sheet"=Sheet,"Foam"=Foam,"Tile"=Tile) #list of groups to compare 
#making a list of lists we created above.  R and other languages use the lists of things often!
bac.venn=gList(venn.diagram(x=bac.venn.list,
                            filename=NULL,
                            label=TRUE,
                            main="Bacterial Communities",
                            main.fontface = 2,
                            fill=c("yellow","blue","green","red","purple"),
                            cat.cex=0.8,
                            cat.fontface=2,
                            lty=1,
                            main.pos=c(0.15,1),
                            cat.just=list(c(0.6,1) , c(0,0) , c(0,0) , c(1,1) ,c(1,0))))
bac.venn.plot=grid.arrange(gTree(children=bac.venn))

#ggsave works with the bac.venn.plot object created above

```

Now for time!  The same logic as Substrate applies here, just different groups.
```{r Venn Time,warning=FALSE}
#extract and shape OTU table at Order level
bacteria.df.venn=subset.data.frame(bacteria.df, taxlevel==4,drop=TRUE)

drops <- c("taxlevel","rankID","daughterlevels","total","SDKC1","SDKC2","SDKC3")
bacteria.df.venn=bacteria.df.venn[ , !(names(bacteria.df.venn) %in% drops)]

bacteria.df.venn=melt(bacteria.df.venn,id.vars="taxon")
bacteria.df.venn=dcast(bacteria.df.venn,variable~bacteria.df.venn$taxon)
#rabund.df$variable=as.numeric(rabund.df$variable)
bacteria.df.venn=separate(bacteria.df.venn,variable,into=c("junk","Date","Substrate"),sep=c(1,7))
bacteria.df.venn=separate(bacteria.df.venn,Substrate,into=c("Substrate","Rep"),sep=c(-1))
bacteria.df.venn$junk=NULL

bacteria.df.venn=droplevels(bacteria.df.venn[-which(bacteria.df.venn$Substrate=='CR'),])
bacteria.df.venn$Date=as.factor(bacteria.df.venn$Date)
bacteria.df.venn$Date=revalue(bacteria.df.venn$Date,c("170818"="3","170828"="10","170905"="21","170915"="31"))

Day_3=colnames(bacteria.df.venn[bacteria.df.venn$Date=="3",apply(bacteria.df.venn[bacteria.df.venn$Date=="3",],MARGIN=2,function(x) any(x>0))])

Day_10=colnames(bacteria.df.venn[bacteria.df.venn$Date=="10",apply(bacteria.df.venn[bacteria.df.venn$Date=="10",],MARGIN=2,function(x) any(x>0))])

Day_21=colnames(bacteria.df.venn[bacteria.df.venn$Date=="21",apply(bacteria.df.venn[bacteria.df.venn$Date=="21",],MARGIN=2,function(x) any(x>0))])

Day_31=colnames(bacteria.df.venn[bacteria.df.venn$Date=="31",apply(bacteria.df.venn[bacteria.df.venn$Date=="31",],MARGIN=2,function(x) any(x>0))])

day_venn=list("Day 3"=Day_3,"Day 10"=Day_10,"Day 21"=Day_21,"Day 31"=Day_31)

bac.venn.day=gList(venn.diagram(x=day_venn,
                            filename=NULL,
                            label=TRUE,
                            main="Bacterial Communities",
                            main.fontface = 2,
                            fill=c("yellow","blue","green","red"),
                            cat.cex=0.8,
                            cat.fontface=2,
                            lty=1,
                            main.pos=c(0.15,1),
                            cat.just=list(c(0.6,1) , c(0,0) , c(0,0) , c(1,1) )))
bac.venn.day.plot=grid.arrange(gTree(children=bac.venn.day)) #don't know how to swithc which date is which blob
```

## Exporting your Working Environment
BY now your working environment (R's short term memory) is pretty full.  This takes time and is not always necessary to do.  One option is to save a copy of it in an .Rdata file.  These files can be opened up and presto! your working environment is back there!  I used these to create a markdown doc of all the figures included in a paper.  It saves time by not requiring me to have all my other R files open and running simultaneously.  These are also handy for archival purposes.

```{r}
saveRDS(bacteria.df,"bacteria.Rdata")  # This saves the working envrionment in a single file.  you can access this file so that you don't need to re-run this document.  For example I did this to create a new markdown doc that cotnained all the figures for this porject but didn't replciate all the analyses.
```

